# Question Answering (Demo)

Until recently, question-answering was considered a complex task. Today you can get good results with just a [linear layer](https://github.com/nlpodyssey/spago/blob/main/pkg/nlp/transformers/bert/spanclassifier.go#L25) on top of the transformer's encoding. Transformers are a recent trend in natural language processing. They are auto-regressive models trained in an unsupervised manner on huge amounts of text to assimilate human language patterns. In other words, they are [super-parrots](https://medium.com/@ElementalCognition/can-super-parrots-ever-achieve-language-understanding-8307dfd3e87c). Although I do not believe that this is the right way to solve the problem of language processing - at least not alone - I have to admit that their power is extraordinary. 

No more talk. Here's how to test a question-answering system based on BERT, the first Transformer.

## Build

To build all of the demos, move into the spaGO directory, and run the following command.

```console
GOARCH=amd64 go build -o bert_server cmd/bert/main.go \
    && go build -o ner-server cmd/ner/main.go \
    && go build -o huggingface_importer cmd/huggingfaceimporter/main.go 
```

If the command is successful you should find several executables called `bert_server`, `ner-server`, and `huggingface_importer` in the same folder.

The Docker image can be built like this.

```console
docker build -t spago:main . -f Dockerfile
```

## Run

If you followed the import step above, now you should see the directory `~/.spago/deepset/bert-base-cased-squad2` containing the original Hugging Face files plus the files generated by spaGO: `spago_model.bin` and `embeddings_storage`. 

Run the `bert_server` indicating a port and the model path (NOT the model file).

Example: 
 
```console
./bert_server server --model=~/.spago/deepset/bert-base-cased-squad2 --tls-disable
```

It should print:

```console
TLS Cert path is /etc/ssl/certs/spago/server.crt
TLS private key path is /etc/ssl/certs/spago/server.key
Start loading pre-trained model from "~/.spago/deepset/bert-base-cased-squad2"
[1/3] Loading configuration... ok
[2/3] Loading vocabulary... ok
[3/3] Loading model weights... ok
Config: {HiddenAct:gelu HiddenSize:768 IntermediateSize:3072 MaxPositionEmbeddings:512 NumAttentionHeads:12 NumHiddenLayers:12 TypeVocabSize:2 VocabSize:28996}
Start TLS server listening on 0.0.0.0:1987.
```

The Docker version of the demo can be run like this. (Note that TLS is not disabled this time.)

```console
docker run --rm -it -p 1987:1987 -v ~/.spago:/tmp/spago spago:main ./bert_server server --model=/tmp/spago/deepset/bert-base-cased-squad2
```

## API

You can easily test the API with the command line using curl.

Set a PASSAGE and a couple of QUESTIONS as environment variables:

```console
PASSAGE="BERT is a technique for NLP developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google."
QUESTION1="Who is the author of BERT?"
QUESTION2="When was BERT created?"
```

To get the answer to the first question, execute:

```console
curl -k -d '{"question": "'"$QUESTION1"'", "passage": "'"$PASSAGE"'"}' -H "Content-Type: application/json" "https://127.0.0.1:1987/answer?pretty"
```

It should print:

```json
{
    "answers": [
        {
            "text": "Jacob Devlin",
            "start": 91,
            "end": 103,
            "confidence": 0.9641588621246571
        }
    ]
}
```

To get the answer to the second question, execute:

```console
curl -k -d '{"question": "'"$QUESTION2"'", "passage": "'"$PASSAGE"'"}' -H "Content-Type: application/json" "https://127.0.0.1:1987/answer?pretty"
```

It should print:

```json
{
    "answers": [
        {
            "text": "2018",
            "start": 83,
            "end": 87,
            "confidence": 0.9924210921706913
        }
    ]
}
```

#### gRPC Client

You can easily test the API with the command line using the build-in gRPC client.

```console
./bert_server client answer --passage="$PASSAGE" --question="$QUESTION1"
```

It should print:

```yaml
answers:
- text: Jacob Devlin
  start: 91
  end: 103
  confidence: 0.9641588621246571
took: 1513
```
